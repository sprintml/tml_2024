{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd:  /home/adam/code/tml_2024\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# Do install: \n",
    "# conda install onnx\n",
    "# conda install onnxruntime\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import json\n",
    "import io\n",
    "import sys\n",
    "import base64\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Tuple\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print('cwd: ', cwd)\n",
    "\n",
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "\n",
    "        self.ids = []\n",
    "        self.imgs = []\n",
    "        self.labels = []\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int]:\n",
    "        id_ = self.ids[index]\n",
    "        img = self.imgs[index]\n",
    "        if not self.transform is None:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[index]\n",
    "        return id_, img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 46612445, 'port': '9002'}\n"
     ]
    }
   ],
   "source": [
    "### REQUESTING NEW API ###\n",
    "TOKEN = \"1\" # to be changed according to your token (given to you for the assignments)\n",
    "\n",
    "response = requests.get(\"http://34.71.138.79:9090\" + \"/stealing_launch\", headers={\"token\": TOKEN})\n",
    "answer = response.json()\n",
    "\n",
    "print(answer)  # {\"seed\": \"SEED\", \"port\": PORT}\n",
    "if 'detail' in answer:\n",
    "    sys.exit(1)\n",
    "\n",
    "# save the values\n",
    "SEED = str(answer['seed'])\n",
    "PORT = str(answer['port'])\n",
    "\n",
    "# SEED = \"1868949\"\n",
    "# PORT = \"9002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### QUERYING THE API ###\n",
    "\n",
    "def model_stealing(images, port):\n",
    "    endpoint = \"/query\"\n",
    "    url = f\"http://34.71.138.79:{port}\" + endpoint\n",
    "    image_data = []\n",
    "    for img in images:\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        img.save(img_byte_arr, format='PNG')\n",
    "        img_byte_arr.seek(0)\n",
    "        img_base64 = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')\n",
    "        image_data.append(img_base64)\n",
    "    \n",
    "    payload = json.dumps(image_data)\n",
    "    response = requests.get(url, files={\"file\": payload}, headers={\"token\": TOKEN})\n",
    "    if response.status_code == 200:\n",
    "        representation = response.json()[\"representations\"]\n",
    "        return representation\n",
    "    else:\n",
    "        raise Exception(\n",
    "            f\"Model stealing failed. Code: {response.status_code}, content: {response.json()}\"\n",
    "        )\n",
    "\n",
    "dataset = torch.load(\"ModelStealingPub.pt\")\n",
    "out = model_stealing([dataset.imgs[idx] for idx in np.random.permutation(1000)], port=PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1024\n",
      "0.8198633193969727\n"
     ]
    }
   ],
   "source": [
    "# 1000 representations in a list\n",
    "print(len(out))\n",
    "\n",
    "# representation 1\n",
    "print(len(out[0]))\n",
    "\n",
    "# first element in the representation\n",
    "print(out[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Store the output in a file.\n",
    "# Be careful to store all the outputs from the API since the number of queries is limited.\n",
    "with open('out.pickle', 'wb') as handle:\n",
    "    pickle.dump(out, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Restore the output from the file.\n",
    "with open('out.pickle', 'rb') as handle:\n",
    "    out = pickle.load(handle)\n",
    "\n",
    "print(len(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'L2': 34.1577262878418}\n"
     ]
    }
   ],
   "source": [
    "#### SUBMISSION ####\n",
    "\n",
    "# Create a dummy model\n",
    "model = nn.Sequential(nn.Flatten(), nn.Linear(32*32*3, 1024))\n",
    "\n",
    "path = 'dummy_submission.onnx'\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    torch.randn(1, 3, 32, 32),\n",
    "    path,\n",
    "    export_params=True,\n",
    "    input_names=[\"x\"],\n",
    ")\n",
    "\n",
    "#### Tests ####\n",
    "\n",
    "# (these are being ran on the eval endpoint for every submission)\n",
    "with open(path, \"rb\") as f:\n",
    "    model = f.read()\n",
    "    try:\n",
    "        stolen_model = ort.InferenceSession(model)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Invalid model, {e=}\")\n",
    "    try:\n",
    "        out = stolen_model.run(\n",
    "            None, {\"x\": np.random.randn(1, 3, 32, 32).astype(np.float32)}\n",
    "        )[0][0]\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Some issue with the input, {e=}\")\n",
    "    assert out.shape == (1024,), \"Invalid output shape\"\n",
    "\n",
    "# Send the model to the server\n",
    "response = requests.post(\"http://34.71.138.79:9090/stealing\", files={\"file\": open(path, \"rb\")}, headers={\"token\": TOKEN, \"seed\": SEED})\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
